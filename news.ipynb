{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "import datetime\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from yahoo_fin import news\n",
        "\n",
        "# TODO: validate ticker input; replace with either argparse or typer\n",
        "# specify the ticker you want to get headlines for\n",
        "ticker = input('Enter a ticker: ').lower()\n",
        "\n",
        "# shows you where this file is located\n",
        "current_dir = Path.cwd()\n",
        "\n",
        "# define filename\n",
        "filename = f\"{ticker}_news.csv\"\n",
        "\n",
        "# adds filename to path\n",
        "filepath = Path(current_dir / \"csv\" / filename)\n",
        "\n",
        "# check if the file exists in the current directory\n",
        "if Path(filepath).is_file():\n",
        "    print(f\"{filename} EXISTS in the current dir\")\n",
        "else:\n",
        "    print(f\"{filename} DOES NOT exist in the current dir\")\n",
        "\n",
        "# get headlines into news_df\n",
        "news_df = news.get_yf_rss(f\"{ticker}\")\n",
        "\n",
        "# Create empty lists for titles and links\n",
        "titles = []\n",
        "links = []\n",
        "\n",
        "# Loop through news items and extract title and link data\n",
        "for news in news_df:\n",
        "    titles.append(news['title'])\n",
        "    links.append(news['link'])\n",
        "\n",
        "# Create a DataFrame from the lists\n",
        "df = pd.DataFrame({'Title': titles, 'Link': links})\n",
        "\n",
        "# addind date column\n",
        "today = datetime.datetime.today().strftime('%Y-%m-%d')\n",
        "df['Date'] = today\n",
        "\n",
        "# check if the file exists\n",
        "if Path(filepath).is_file():\n",
        "    # read the existing data into a dataframe\n",
        "    df2 = pd.read_csv(filepath)\n",
        "\n",
        "    # merge the existing data with the new data\n",
        "    appended_df = pd.merge(df2, df, how='outer')\n",
        "\n",
        "    # save the appended data to the same file\n",
        "    appended_df.to_csv(filepath, index=False)\n",
        "\n",
        "    print(f\"new data was added\")\n",
        "else:\n",
        "    # save the new data to a new file with the specified filename\n",
        "    df.to_csv(filepath, index=False)\n",
        "\n",
        "    print(f\"{filename} was created\")\n",
        "\n",
        "# reloading csv to handle duplicates\n",
        "news = pd.read_csv(filepath)\n",
        "\n",
        "# checking for duplicates\n",
        "duplicates = news[news.duplicated(subset=['Title'])]\n",
        "\n",
        "# Remove duplicates\n",
        "news.drop_duplicates(subset=['Title'], inplace=True)\n",
        "\n",
        "df = news\n",
        "df.to_csv(filepath, index=False)\n",
        "print(f\"{filename} resaved sans duplicates\")\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}